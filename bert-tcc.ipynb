{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"01774970c0c247ec8820b225f445100a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02b9512abd7b415aa7b2773a5baf62f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_705ec28795a048a5ae3e2f686808ea3f","IPY_MODEL_0fbfa91ed324471bb9b78a6ae119fee3"],"layout":"IPY_MODEL_ae8b5dccbe14449baf1b54ee57adf912"}},"0fbfa91ed324471bb9b78a6ae119fee3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01774970c0c247ec8820b225f445100a","placeholder":"​","style":"IPY_MODEL_9cb47d2cc6df4fae87fbb4721de7f831","value":" 153164/153164 [06:21&lt;00:00, 401.20it/s]"}},"1444a5938b2f40b692a70e1be8f60d2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cfa4c471fdf40fea6e34cb76a722ad1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"1d398837b45b4839963b39192fe6c75d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36399fa70d414344b273a5b5e1030a28","placeholder":"​","style":"IPY_MODEL_2ecf8ad2a86c47f1b77933597b1ddf81","value":" 4488/? [33:53&lt;00:00,  2.21it/s]"}},"295c13581d5c43eba2979147eda8b0f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ac04ff84d65412ca6c6bd66fc7d9b90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ecf8ad2a86c47f1b77933597b1ddf81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32d28aface47454aa7032e9541c4041a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"36399fa70d414344b273a5b5e1030a28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c292a9046be454c840145d6cc40f3c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41f9a2393d8b439b93a6410606b5846b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98b9a1e43290471d88e6e67d0887ca26","max":498,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1cfa4c471fdf40fea6e34cb76a722ad1","value":498}},"42ab008085e34b4dbe667ef7ac1a9cfd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8028941778e4b609bc7fb363ec66511","placeholder":"​","style":"IPY_MODEL_7b1920e685ea494e8ecfbca88ae58e3c","value":" 4787/? [11:58&lt;00:00,  6.66it/s]"}},"58946f23ad4145e281ff394f574a3e7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"5b5f4efe590047bf9ac287234c97dcac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62886b9c986c4c51b28926798ca6377c","max":4487,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58946f23ad4145e281ff394f574a3e7a","value":4487}},"5f0f2d010da847089d50d79f0ddd15ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_295c13581d5c43eba2979147eda8b0f9","placeholder":"​","style":"IPY_MODEL_9905683a667947c5a7f279f09ae97e84","value":" 132567/159571 [05:37&lt;01:08, 392.11it/s]"}},"62886b9c986c4c51b28926798ca6377c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"705ec28795a048a5ae3e2f686808ea3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_9bebee4fa8fa487c8f27c37aac31e55e","max":153164,"min":0,"orientation":"horizontal","style":"IPY_MODEL_763ca21e7228489eb781be52b6c43382","value":153164}},"763ca21e7228489eb781be52b6c43382":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"7b1920e685ea494e8ecfbca88ae58e3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98b9a1e43290471d88e6e67d0887ca26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9905683a667947c5a7f279f09ae97e84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a364032f7304123a4e39f735b5769c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0a98c6db53449e894b47f46d297de35","IPY_MODEL_5f0f2d010da847089d50d79f0ddd15ea"],"layout":"IPY_MODEL_bf1675b061374df481ae251f68b2e8fe"}},"9bebee4fa8fa487c8f27c37aac31e55e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cb47d2cc6df4fae87fbb4721de7f831":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d209ec3a82b4607af3cbc42fd0577e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1b2d2f8683e4a32b8366f344325086b","placeholder":"​","style":"IPY_MODEL_2ac04ff84d65412ca6c6bd66fc7d9b90","value":" 499/? [07:42&lt;00:00,  1.08it/s]"}},"a1b2d2f8683e4a32b8366f344325086b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae8b5dccbe14449baf1b54ee57adf912":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b72e7efc80db44d0938f1a7cab1a903b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b5f4efe590047bf9ac287234c97dcac","IPY_MODEL_1d398837b45b4839963b39192fe6c75d"],"layout":"IPY_MODEL_3c292a9046be454c840145d6cc40f3c9"}},"b8028941778e4b609bc7fb363ec66511":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8d4640eee204aeea499d745ce6e5b54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1444a5938b2f40b692a70e1be8f60d2b","max":4786,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32d28aface47454aa7032e9541c4041a","value":4786}},"bf1675b061374df481ae251f68b2e8fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c071ec29c3c34f45b030b5a23ef9b6d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"cb0dc723963e45cba0508ba328af75f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41f9a2393d8b439b93a6410606b5846b","IPY_MODEL_9d209ec3a82b4607af3cbc42fd0577e6"],"layout":"IPY_MODEL_e22f132646684acb8b47ec12d569bfa0"}},"e22f132646684acb8b47ec12d569bfa0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2bf3da854af40709d525173ed2ece20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8d4640eee204aeea499d745ce6e5b54","IPY_MODEL_42ab008085e34b4dbe667ef7ac1a9cfd"],"layout":"IPY_MODEL_f2665aaaf7af45708c32d3bfa0099d95"}},"e5d5d499b57b4019ae5d47109cecc0f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0a98c6db53449e894b47f46d297de35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":" 83%","description_tooltip":null,"layout":"IPY_MODEL_e5d5d499b57b4019ae5d47109cecc0f0","max":159571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c071ec29c3c34f45b030b5a23ef9b6d4","value":132567}},"f2665aaaf7af45708c32d3bfa0099d95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BERT TCC","metadata":{}},{"cell_type":"markdown","source":"Installing the missing libraries (w.r.t. Kaggle).","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade git+https://github.com/huggingface/transformers.git\n!pip install keras_preprocessing","metadata":{"execution":{"iopub.status.busy":"2023-07-17T22:04:24.854751Z","iopub.execute_input":"2023-07-17T22:04:24.855190Z","iopub.status.idle":"2023-07-17T22:05:08.882894Z","shell.execute_reply.started":"2023-07-17T22:04:24.855150Z","shell.execute_reply":"2023-07-17T22:05:08.881643Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mCollecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-xddvuz1l\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-xddvuz1l\n  Resolved https://github.com/huggingface/transformers.git to commit 2ab75add4b30c2fc44a8bf575156d448d9ed87a7\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.32.0.dev0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (2023.5.7)\n\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: keras_preprocessing in /opt/conda/lib/python3.10/site-packages (1.1.2)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras_preprocessing) (1.23.5)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from keras_preprocessing) (1.16.0)\n\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"Importing libraries.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom transformers import BertTokenizer\nfrom keras_preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport torchmetrics\nimport torch","metadata":{"id":"aGa2jmNmCjXf","execution":{"iopub.status.busy":"2023-07-17T22:05:08.890537Z","iopub.execute_input":"2023-07-17T22:05:08.890878Z","iopub.status.idle":"2023-07-17T22:05:15.142709Z","shell.execute_reply.started":"2023-07-17T22:05:08.890840Z","shell.execute_reply":"2023-07-17T22:05:15.141718Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Loading the datasets.","metadata":{}},{"cell_type":"code","source":"label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\ndf_train = pd.read_csv('/kaggle/input/tcc-input/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tcc-input/test.csv')\ndf_test_labels = pd.read_csv('/kaggle/input/tcc-input/test_labels.csv')\ndf_test_labels = df_test_labels.set_index('id')","metadata":{"id":"50uZZZzH_NDV","outputId":"f925ad52-96d5-47a1-b573-db6fa12012ba","execution":{"iopub.status.busy":"2023-07-17T22:05:15.144137Z","iopub.execute_input":"2023-07-17T22:05:15.144485Z","iopub.status.idle":"2023-07-17T22:05:17.184472Z","shell.execute_reply.started":"2023-07-17T22:05:15.144449Z","shell.execute_reply":"2023-07-17T22:05:17.183366Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing (Tokenization, Truncation & Padding).","metadata":{}},{"cell_type":"code","source":"bert_model_name = 'bert-base-uncased'\n\ntokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=True)\nMAX_LEN = 128\n\ndef tokenize_sentences(sentences, tokenizer, max_seq_len = 128):\n    tokenized_sentences = []\n\n    for sentence in sentences:\n        tokenized_sentence = tokenizer.encode(\n                            sentence,                  # Sentence to encode.\n                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n                            max_length = max_seq_len,  # Truncate all sentences.\n                    )\n        \n        tokenized_sentences.append(tokenized_sentence)\n\n    return tokenized_sentences\n\ndef create_attention_masks(tokenized_and_padded_sentences):\n    attention_masks = []\n\n    for sentence in tokenized_and_padded_sentences:\n        att_mask = [int(token_id > 0) for token_id in sentence]\n        attention_masks.append(att_mask)\n\n    return np.asarray(attention_masks)\n\ninput_ids = tokenize_sentences(df_train['comment_text'], tokenizer, MAX_LEN)\ninput_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\nattention_masks = create_attention_masks(input_ids)","metadata":{"id":"g-8WnPfD_35q","outputId":"ef31e72c-9dc5-4e7d-875e-875758466538","execution":{"iopub.status.busy":"2023-07-17T22:05:17.187851Z","iopub.execute_input":"2023-07-17T22:05:17.188394Z","iopub.status.idle":"2023-07-17T22:12:57.150449Z","shell.execute_reply.started":"2023-07-17T22:05:17.188335Z","shell.execute_reply":"2023-07-17T22:12:57.149289Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"}]},{"cell_type":"code","source":"labels =  df_train[label_cols].values\n\ntrain_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=0, test_size=0.1)\ntrain_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=0, test_size=0.1)\n\ntrain_size = len(train_inputs)\nvalidation_size = len(validation_inputs)","metadata":{"id":"bMumeio9FFds","execution":{"iopub.status.busy":"2023-07-17T22:12:57.151950Z","iopub.execute_input":"2023-07-17T22:12:57.152429Z","iopub.status.idle":"2023-07-17T22:12:57.332374Z","shell.execute_reply.started":"2023-07-17T22:12:57.152393Z","shell.execute_reply":"2023-07-17T22:12:57.330831Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Creating efficient data pipelines using tf.data.","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nNR_EPOCHS = 1\n\ndef create_dataset(data_tuple, epochs=1, batch_size=32, buffer_size=10000, train=True):\n    dataset = tf.data.Dataset.from_tensor_slices(data_tuple)\n    if train:\n        dataset = dataset.shuffle(buffer_size=buffer_size)\n    dataset = dataset.repeat(epochs)\n    dataset = dataset.batch(batch_size)\n    if train:\n        dataset = dataset.prefetch(1)\n    \n    return dataset\n\ntrain_dataset = create_dataset((train_inputs, train_masks, train_labels), epochs=NR_EPOCHS, batch_size=BATCH_SIZE)\nvalidation_dataset = create_dataset((validation_inputs, validation_masks, validation_labels), epochs=NR_EPOCHS, batch_size=BATCH_SIZE)","metadata":{"id":"H99t9YNDFcRq","execution":{"iopub.status.busy":"2023-07-17T22:12:57.333917Z","iopub.execute_input":"2023-07-17T22:12:57.334308Z","iopub.status.idle":"2023-07-17T22:13:03.407669Z","shell.execute_reply.started":"2023-07-17T22:12:57.334273Z","shell.execute_reply":"2023-07-17T22:13:03.406625Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Model Setup\n- Load the pretrained BERT base-model from Transformers library\n- Take the first hidden-state from BERT output (corresponding to CLS token) and feed it into a Dense layer with 6 neurons and sigmoid activation (Classifier). The outputs of this layer can be interpreted as probabilities for each of the 6 classes.","metadata":{}},{"cell_type":"code","source":"from transformers import TFBertModel\nfrom tensorflow.keras.layers import Dense, Flatten\n\nclass BertClassifier(tf.keras.Model):    \n    def __init__(self, bert: TFBertModel, num_classes: int):\n        super().__init__()\n        self.bert = bert\n        self.classifier = Dense(num_classes, activation='sigmoid')\n        \n    @tf.function\n    def call(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None):\n        outputs = self.bert(input_ids,\n                               attention_mask=attention_mask,\n                               token_type_ids=token_type_ids,\n                               position_ids=position_ids,\n                               head_mask=head_mask)\n        cls_output = outputs[1]\n        cls_output = self.classifier(cls_output)\n                \n        return cls_output\n\nmodel = BertClassifier(TFBertModel.from_pretrained(bert_model_name), len(label_cols))","metadata":{"id":"3Zp6X7meF_T5","execution":{"iopub.status.busy":"2023-07-17T22:13:03.409379Z","iopub.execute_input":"2023-07-17T22:13:03.409788Z","iopub.status.idle":"2023-07-17T22:13:06.066541Z","shell.execute_reply.started":"2023-07-17T22:13:03.409755Z","shell.execute_reply":"2023-07-17T22:13:06.065610Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training\n- Use BinaryCrossentropy as loss function (is calculated for each of the output 6 output neurons ...that's like training 6 binary classification tasks at the same time) \n- Use the AdamW optimizer with 1-cycle-policy from the Transformers library\n- AUC evaluation metrics","metadata":{}},{"cell_type":"code","source":"import time\nfrom transformers import create_optimizer\n\nsteps_per_epoch = train_size // BATCH_SIZE\nvalidation_steps = validation_size // BATCH_SIZE\n\n# | Loss Function\nloss_object = tf.keras.losses.BinaryCrossentropy(from_logits=False)\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\nvalidation_loss = tf.keras.metrics.Mean(name='test_loss')\n\n# | Optimizer (with 1-cycle-policy)\nwarmup_steps = steps_per_epoch // 3\ntotal_steps = steps_per_epoch * NR_EPOCHS - warmup_steps\noptimizer,lr = create_optimizer(init_lr=2e-5, num_train_steps=total_steps, num_warmup_steps=warmup_steps)\n\n# | Metrics\ntrain_auc_metrics = [tf.keras.metrics.AUC() for i in range(len(label_cols))]\nvalidation_auc_metrics = [tf.keras.metrics.AUC() for i in range(len(label_cols))]\n\n@tf.function\ndef train_step(model, token_ids, masks, labels):\n    labels = tf.dtypes.cast(labels, tf.float32)\n\n    with tf.GradientTape() as tape:\n        predictions = model(token_ids, attention_mask=masks)\n        loss = loss_object(labels, predictions)\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss(loss)\n\n    for i, auc in enumerate(train_auc_metrics):\n        auc.update_state(labels[:,i], predictions[:,i])\n        \n@tf.function\ndef validation_step(model, token_ids, masks, labels):\n    labels = tf.dtypes.cast(labels, tf.float32)\n\n    predictions = model(token_ids, attention_mask=masks, training=False)\n    v_loss = loss_object(labels, predictions)\n\n    validation_loss(v_loss)\n    for i, auc in enumerate(validation_auc_metrics):\n        auc.update_state(labels[:,i], predictions[:,i])\n                                              \ndef train(model, train_dataset, val_dataset, train_steps_per_epoch, val_steps_per_epoch, epochs):\n    for epoch in range(epochs):\n        print('=' * 50, f\"EPOCH {epoch}\", '=' * 50)\n\n        start = time.time()\n\n        for i, (token_ids, masks, labels) in enumerate(train_dataset):\n            train_step(model, token_ids, masks, labels)\n            if i % 1000 == 0:\n                print(f'\\nTrain Step: {i}, Loss: {train_loss.result()}')\n                for i, label_name in enumerate(label_cols):\n                    print(f\"{label_name} roc_auc {train_auc_metrics[i].result()}\")\n                    train_auc_metrics[i].reset_states()\n        \n        for i, (token_ids, masks, labels) in enumerate(val_dataset):\n            validation_step(model, token_ids, masks, labels)\n\n        print(f'\\nEpoch {epoch+1}, Validation Loss: {validation_loss.result()}, Time: {time.time()-start}\\n')\n\n        for i, label_name in enumerate(label_cols):\n            print(f\"{label_name} roc_auc {validation_auc_metrics[i].result()}\")\n            validation_auc_metrics[i].reset_states()\n\n        print('\\n')\n\n        \ntrain(model, train_dataset, validation_dataset, train_steps_per_epoch=steps_per_epoch, val_steps_per_epoch=validation_steps, epochs=NR_EPOCHS)","metadata":{"id":"cJsVaX4qqoM0","outputId":"52dfd86b-a8f4-48f5-c481-a9db4f5c40fa","execution":{"iopub.status.busy":"2023-07-17T22:13:06.068186Z","iopub.execute_input":"2023-07-17T22:13:06.068585Z","iopub.status.idle":"2023-07-17T23:11:53.720603Z","shell.execute_reply.started":"2023-07-17T22:13:06.068531Z","shell.execute_reply":"2023-07-17T23:11:53.719609Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"================================================== EPOCH 0 ==================================================\n\nTrain Step: 0, Loss: 0.8777700662612915\ntoxic roc_auc 0.5919540524482727\nsevere_toxic roc_auc 0.0\nobscene roc_auc 0.9666666984558105\nthreat roc_auc 0.0\ninsult roc_auc 0.774193525314331\nidentity_hate roc_auc 0.0\n\nTrain Step: 1000, Loss: 0.16125765442848206\ntoxic roc_auc 0.9068880677223206\nsevere_toxic roc_auc 0.9035217761993408\nobscene roc_auc 0.8813758492469788\nthreat roc_auc 0.6678696870803833\ninsult roc_auc 0.9054983854293823\nidentity_hate roc_auc 0.8091147541999817\n\nTrain Step: 2000, Loss: 0.10315146297216415\ntoxic roc_auc 0.978399932384491\nsevere_toxic roc_auc 0.9834991693496704\nobscene roc_auc 0.9860031604766846\nthreat roc_auc 0.9332062602043152\ninsult roc_auc 0.9827759265899658\nidentity_hate roc_auc 0.9654219150543213\n\nTrain Step: 3000, Loss: 0.08222710341215134\ntoxic roc_auc 0.9837983846664429\nsevere_toxic roc_auc 0.9872028827667236\nobscene roc_auc 0.9900631308555603\nthreat roc_auc 0.9481101036071777\ninsult roc_auc 0.9853754043579102\nidentity_hate roc_auc 0.972629964351654\n\nTrain Step: 4000, Loss: 0.07120407372713089\ntoxic roc_auc 0.9842954277992249\nsevere_toxic roc_auc 0.9875302910804749\nobscene roc_auc 0.9903566241264343\nthreat roc_auc 0.9720190763473511\ninsult roc_auc 0.9877721071243286\nidentity_hate roc_auc 0.9862080812454224\n\nEpoch 1, Validation Loss: 0.038133956491947174, Time: 3527.525886297226\n\ntoxic roc_auc 0.986725389957428\nsevere_toxic roc_auc 0.9880314469337463\nobscene roc_auc 0.9912036061286926\nthreat roc_auc 0.9693261384963989\ninsult roc_auc 0.9856164455413818\nidentity_hate roc_auc 0.9770253896713257\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"test_input_ids = tokenize_sentences(df_test['comment_text'], tokenizer, MAX_LEN)\ntest_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\ntest_attention_masks = create_attention_masks(test_input_ids)","metadata":{"id":"cdShHpPfH3es","outputId":"94b89833-244c-4cde-e6f6-637594ddef4b","execution":{"iopub.status.busy":"2023-07-17T23:11:53.722065Z","iopub.execute_input":"2023-07-17T23:11:53.722445Z","iopub.status.idle":"2023-07-17T23:18:47.373806Z","shell.execute_reply.started":"2023-07-17T23:11:53.722408Z","shell.execute_reply":"2023-07-17T23:18:47.372736Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"TEST_BATCH_SIZE = 32\ntest_steps = len(df_test) // TEST_BATCH_SIZE\n\ntest_dataset = create_dataset((test_input_ids, test_attention_masks), batch_size=TEST_BATCH_SIZE, train=False, epochs=1)\n\ndf_predictions = pd.read_csv(\"/kaggle/input/tcc-input/sample_submission.csv\", index_col='id')\n\nfor i, (token_ids, masks) in enumerate(test_dataset):\n    sample_ids = df_test.iloc[i*TEST_BATCH_SIZE:(i+1)*TEST_BATCH_SIZE]['id']\n    predictions = model(token_ids, attention_mask=masks).numpy()\n\n    df_predictions.loc[sample_ids, label_cols] = predictions","metadata":{"id":"RUAKdp2EKYlZ","outputId":"29f3b4bc-2c0c-43cb-f873-1b0db86865d3","execution":{"iopub.status.busy":"2023-07-17T23:18:47.375551Z","iopub.execute_input":"2023-07-17T23:18:47.376238Z","iopub.status.idle":"2023-07-17T23:39:51.042300Z","shell.execute_reply.started":"2023-07-17T23:18:47.376200Z","shell.execute_reply":"2023-07-17T23:39:51.041145Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Rows with -1 values in test_labels are not used for evaluation.\nTherefore, we remove them from both test_labels and df_predictions.","metadata":{}},{"cell_type":"code","source":"indexes = []\nfor index, row in df_test_labels.iterrows():\n    if row['toxic'] == -1:\n        indexes.append(index)\n        \ntest_labels = df_test_labels.drop(indexes)\npredictions = df_predictions.drop(indexes)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T23:39:51.044132Z","iopub.execute_input":"2023-07-17T23:39:51.044525Z","iopub.status.idle":"2023-07-17T23:39:58.336066Z","shell.execute_reply.started":"2023-07-17T23:39:51.044489Z","shell.execute_reply":"2023-07-17T23:39:58.335008Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Calculating ROC AUC score for each category.","metadata":{}},{"cell_type":"code","source":"for cat in label_cols:\n    \n    print(f\"Category: {cat}\")\n    print(f\"Sklearn score: {metrics.roc_auc_score(test_labels[cat], predictions[cat], multi_class='ovr')}\")\n    print(f\"torchmetrics score: {torchmetrics.functional.classification.binary_auroc(torch.tensor(predictions[cat].values),torch.tensor(test_labels[cat].values), thresholds=None)}\")\n    print(\"#\" * 30)\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T23:39:58.337553Z","iopub.execute_input":"2023-07-17T23:39:58.337953Z","iopub.status.idle":"2023-07-17T23:39:58.517193Z","shell.execute_reply.started":"2023-07-17T23:39:58.337917Z","shell.execute_reply":"2023-07-17T23:39:58.516043Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Category: toxic\nSklearn score: 0.9724607582639623\ntorchmetrics score: 0.9724607467651367\n##############################\n\nCategory: severe_toxic\nSklearn score: 0.9903543707866406\ntorchmetrics score: 0.9903543591499329\n##############################\n\nCategory: obscene\nSklearn score: 0.9801292509809383\ntorchmetrics score: 0.9801293015480042\n##############################\n\nCategory: threat\nSklearn score: 0.9921004617149952\ntorchmetrics score: 0.9921004772186279\n##############################\n\nCategory: insult\nSklearn score: 0.9792798626533823\ntorchmetrics score: 0.9792798757553101\n##############################\n\nCategory: identity_hate\nSklearn score: 0.9894588329922847\ntorchmetrics score: 0.9894588589668274\n##############################\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Calculating mean column-wise ROC AUC score on all categories.","metadata":{}},{"cell_type":"code","source":"print(f\"Sklearn score: {metrics.roc_auc_score(test_labels[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values, predictions[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values, average='macro')}\")\nprint(F\"Torchmetrics score: {torchmetrics.functional.classification.multilabel_auroc(torch.tensor(predictions[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values),torch.tensor(test_labels[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values),num_labels=6,thresholds=None )}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-17T23:39:58.520904Z","iopub.execute_input":"2023-07-17T23:39:58.521210Z","iopub.status.idle":"2023-07-17T23:39:58.707380Z","shell.execute_reply.started":"2023-07-17T23:39:58.521184Z","shell.execute_reply":"2023-07-17T23:39:58.706339Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Sklearn score: 0.9839639228987006\nTorchmetrics score: 0.9839639663696289\n","output_type":"stream"}]}]}